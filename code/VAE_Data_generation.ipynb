{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4fbd872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\balun\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c3d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.mean_squared_error(data, reconstruction)\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            \n",
    "            # Additional loss term for categorical variables\n",
    "            categorical_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(data[:, -3:], reconstruction[:, -3:])\n",
    "            )\n",
    "            # Weight for the categorical loss\n",
    "            alpha = 0.5  # Adjust this weight as needed\n",
    "            total_loss = reconstruction_loss + kl_loss + alpha * categorical_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        return {\n",
    "            \"loss\": total_loss,\n",
    "            \"reconstruction_loss\": reconstruction_loss,\n",
    "            \"kl_loss\": kl_loss,\n",
    "            \"categorical_loss\": categorical_loss,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa605500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\balun\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\balun\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the encoder and decoder networks\n",
    "original_dim = 16  #includeing one-hot encoded columns\n",
    "latent_dim = 2\n",
    "intermediate_dim = 64\n",
    "\n",
    "# Encoder network\n",
    "inputs = Input(shape=(original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z])\n",
    "\n",
    "# Decoder network\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "h_decoded = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(h_decoded)\n",
    "decoder = Model(latent_inputs, outputs)\n",
    "\n",
    "# Define the VAE model\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fc160d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C          H         N          O         S         VM        Ash  \\\n",
      "0  49.270000   6.550000  1.560000  42.620000  0.000000  80.752916   6.044539   \n",
      "1  45.019652   6.569343  2.189781  46.221224  0.000000  76.122673  18.948521   \n",
      "2  45.739910  10.762332  7.036909  34.908589  1.552259  49.357766  42.020000   \n",
      "3  56.085157   7.108220  4.861029  30.833826  1.111768  73.526474  20.879121   \n",
      "4  45.896172   5.709845  1.622249  46.771734  0.000000  77.318919   1.783784   \n",
      "\n",
      "          FC    Cel    Hem    Lig Location  Plantcapacity(kg/hr     MSP  \n",
      "0  13.202545  36.89  20.42  17.38       UK                50000  1.0088  \n",
      "1   4.928806  21.00  28.00  21.00       UK                25000  0.6864  \n",
      "2   8.626970  35.00  25.00  26.50       US                25000  0.8500  \n",
      "3   5.594406  16.60  48.50   1.60       UK                25000  0.7384  \n",
      "4  20.897297  21.00  12.80  32.70       US                25000  0.7300  \n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "Data = pd.read_excel('Dataset.xlsx')\n",
    "Data = Data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Clean column names\n",
    "cleaned_columns = {\n",
    "    col: col.replace(' ', '').replace('(%', '').replace(')','').replace('\\n', '')\n",
    "    for col in Data.columns\n",
    "}\n",
    "Data.rename(columns=cleaned_columns, inplace=True)\n",
    "\n",
    "#DataFrame has clean column names\n",
    "print(Data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b83ae944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C          H         N          O         S         VM        Ash  \\\n",
      "0  49.270000   6.550000  1.560000  42.620000  0.000000  80.752916   6.044539   \n",
      "1  45.019652   6.569343  2.189781  46.221224  0.000000  76.122673  18.948521   \n",
      "2  45.739910  10.762332  7.036909  34.908589  1.552259  49.357766  42.020000   \n",
      "3  56.085157   7.108220  4.861029  30.833826  1.111768  73.526474  20.879121   \n",
      "4  45.896172   5.709845  1.622249  46.771734  0.000000  77.318919   1.783784   \n",
      "\n",
      "          FC    Cel    Hem    Lig  Plantcapacity(kg/hr     MSP  \\\n",
      "0  13.202545  36.89  20.42  17.38                50000  1.0088   \n",
      "1   4.928806  21.00  28.00  21.00                25000  0.6864   \n",
      "2   8.626970  35.00  25.00  26.50                25000  0.8500   \n",
      "3   5.594406  16.60  48.50   1.60                25000  0.7384   \n",
      "4  20.897297  21.00  12.80  32.70                25000  0.7300   \n",
      "\n",
      "   Location_China  Location_UK  Location_US  \n",
      "0               0            1            0  \n",
      "1               0            1            0  \n",
      "2               0            0            1  \n",
      "3               0            1            0  \n",
      "4               0            0            1  \n"
     ]
    }
   ],
   "source": [
    "data = pd.get_dummies(Data, columns= ['Location'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07b8b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 55ms/step - loss: 0.5242 - reconstruction_loss: 0.1317 - kl_loss: 0.0332 - categorical_loss: 0.7187 - val_loss: 0.0000e+00\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4878 - reconstruction_loss: 0.1283 - kl_loss: 0.0223 - categorical_loss: 0.6982 - val_loss: 0.0000e+00\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5027 - reconstruction_loss: 0.1281 - kl_loss: 0.0197 - categorical_loss: 0.7003 - val_loss: 0.0000e+00\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4739 - reconstruction_loss: 0.1241 - kl_loss: 0.0135 - categorical_loss: 0.6875 - val_loss: 0.0000e+00\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4702 - reconstruction_loss: 0.1223 - kl_loss: 0.0109 - categorical_loss: 0.6797 - val_loss: 0.0000e+00\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4693 - reconstruction_loss: 0.1209 - kl_loss: 0.0087 - categorical_loss: 0.6772 - val_loss: 0.0000e+00\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4634 - reconstruction_loss: 0.1185 - kl_loss: 0.0068 - categorical_loss: 0.6722 - val_loss: 0.0000e+00\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4523 - reconstruction_loss: 0.1162 - kl_loss: 0.0059 - categorical_loss: 0.6689 - val_loss: 0.0000e+00\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4523 - reconstruction_loss: 0.1151 - kl_loss: 0.0046 - categorical_loss: 0.6633 - val_loss: 0.0000e+00\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4465 - reconstruction_loss: 0.1124 - kl_loss: 0.0045 - categorical_loss: 0.6597 - val_loss: 0.0000e+00\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4344 - reconstruction_loss: 0.1110 - kl_loss: 0.0037 - categorical_loss: 0.6559 - val_loss: 0.0000e+00\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4481 - reconstruction_loss: 0.1127 - kl_loss: 0.0033 - categorical_loss: 0.6539 - val_loss: 0.0000e+00\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4445 - reconstruction_loss: 0.1096 - kl_loss: 0.0033 - categorical_loss: 0.6516 - val_loss: 0.0000e+00\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4485 - reconstruction_loss: 0.1081 - kl_loss: 0.0029 - categorical_loss: 0.6570 - val_loss: 0.0000e+00\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4310 - reconstruction_loss: 0.1068 - kl_loss: 0.0027 - categorical_loss: 0.6482 - val_loss: 0.0000e+00\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4315 - reconstruction_loss: 0.1061 - kl_loss: 0.0024 - categorical_loss: 0.6447 - val_loss: 0.0000e+00\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4175 - reconstruction_loss: 0.1025 - kl_loss: 0.0022 - categorical_loss: 0.6454 - val_loss: 0.0000e+00\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4213 - reconstruction_loss: 0.1017 - kl_loss: 0.0019 - categorical_loss: 0.6450 - val_loss: 0.0000e+00\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4171 - reconstruction_loss: 0.1008 - kl_loss: 0.0019 - categorical_loss: 0.6406 - val_loss: 0.0000e+00\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4229 - reconstruction_loss: 0.1018 - kl_loss: 0.0018 - categorical_loss: 0.6413 - val_loss: 0.0000e+00\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4297 - reconstruction_loss: 0.1027 - kl_loss: 0.0015 - categorical_loss: 0.6452 - val_loss: 0.0000e+00\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4103 - reconstruction_loss: 0.0993 - kl_loss: 0.0015 - categorical_loss: 0.6365 - val_loss: 0.0000e+00\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4275 - reconstruction_loss: 0.1025 - kl_loss: 0.0015 - categorical_loss: 0.6414 - val_loss: 0.0000e+00\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4081 - reconstruction_loss: 0.0982 - kl_loss: 0.0013 - categorical_loss: 0.6344 - val_loss: 0.0000e+00\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4172 - reconstruction_loss: 0.0972 - kl_loss: 0.0013 - categorical_loss: 0.6423 - val_loss: 0.0000e+00\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4279 - reconstruction_loss: 0.1011 - kl_loss: 0.0013 - categorical_loss: 0.6377 - val_loss: 0.0000e+00\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4227 - reconstruction_loss: 0.0987 - kl_loss: 0.0012 - categorical_loss: 0.6389 - val_loss: 0.0000e+00\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4174 - reconstruction_loss: 0.0968 - kl_loss: 0.0011 - categorical_loss: 0.6442 - val_loss: 0.0000e+00\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4230 - reconstruction_loss: 0.0984 - kl_loss: 0.0011 - categorical_loss: 0.6406 - val_loss: 0.0000e+00\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4092 - reconstruction_loss: 0.0965 - kl_loss: 9.7939e-04 - categorical_loss: 0.6383 - val_loss: 0.0000e+00\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4070 - reconstruction_loss: 0.0962 - kl_loss: 0.0011 - categorical_loss: 0.6351 - val_loss: 0.0000e+00\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4073 - reconstruction_loss: 0.0944 - kl_loss: 9.6717e-04 - categorical_loss: 0.6348 - val_loss: 0.0000e+00\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4229 - reconstruction_loss: 0.0983 - kl_loss: 9.0743e-04 - categorical_loss: 0.6361 - val_loss: 0.0000e+00\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4207 - reconstruction_loss: 0.0961 - kl_loss: 9.0170e-04 - categorical_loss: 0.6387 - val_loss: 0.0000e+00\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4146 - reconstruction_loss: 0.0946 - kl_loss: 8.5888e-04 - categorical_loss: 0.6377 - val_loss: 0.0000e+00\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4125 - reconstruction_loss: 0.0956 - kl_loss: 8.0338e-04 - categorical_loss: 0.6374 - val_loss: 0.0000e+00\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4128 - reconstruction_loss: 0.0956 - kl_loss: 8.3797e-04 - categorical_loss: 0.6387 - val_loss: 0.0000e+00\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4047 - reconstruction_loss: 0.0948 - kl_loss: 8.8992e-04 - categorical_loss: 0.6337 - val_loss: 0.0000e+00\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4057 - reconstruction_loss: 0.0938 - kl_loss: 8.2015e-04 - categorical_loss: 0.6359 - val_loss: 0.0000e+00\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4319 - reconstruction_loss: 0.0995 - kl_loss: 8.8674e-04 - categorical_loss: 0.6368 - val_loss: 0.0000e+00\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4179 - reconstruction_loss: 0.0957 - kl_loss: 8.2424e-04 - categorical_loss: 0.6431 - val_loss: 0.0000e+00\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4339 - reconstruction_loss: 0.0991 - kl_loss: 8.5794e-04 - categorical_loss: 0.6409 - val_loss: 0.0000e+00\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4001 - reconstruction_loss: 0.0927 - kl_loss: 8.1679e-04 - categorical_loss: 0.6350 - val_loss: 0.0000e+00\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4085 - reconstruction_loss: 0.0949 - kl_loss: 8.0656e-04 - categorical_loss: 0.6365 - val_loss: 0.0000e+00\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4233 - reconstruction_loss: 0.0959 - kl_loss: 8.7029e-04 - categorical_loss: 0.6390 - val_loss: 0.0000e+00\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4130 - reconstruction_loss: 0.0957 - kl_loss: 7.0757e-04 - categorical_loss: 0.6355 - val_loss: 0.0000e+00\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4178 - reconstruction_loss: 0.0939 - kl_loss: 7.0438e-04 - categorical_loss: 0.6439 - val_loss: 0.0000e+00\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4168 - reconstruction_loss: 0.0941 - kl_loss: 7.2324e-04 - categorical_loss: 0.6374 - val_loss: 0.0000e+00\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4102 - reconstruction_loss: 0.0956 - kl_loss: 7.6460e-04 - categorical_loss: 0.6321 - val_loss: 0.0000e+00\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4176 - reconstruction_loss: 0.0950 - kl_loss: 7.4227e-04 - categorical_loss: 0.6371 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1cd70fcb7c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_data = data.iloc[:, :-3].values\n",
    "binary_data = data.iloc[:, -3:].values\n",
    "\n",
    "# Normalize the continuous features\n",
    "scaler = MinMaxScaler()\n",
    "continuous_data_normalized = scaler.fit_transform(continuous_data)\n",
    "\n",
    "# Concatenate with the binary data to get the normalized data\n",
    "normalized_data = np.concatenate([continuous_data_normalized, binary_data], axis=1)\n",
    "\n",
    "# Train/test split\n",
    "x_train, x_test = train_test_split(normalized_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the VAE\n",
    "vae.fit(x_train, x_train, epochs=50, batch_size=32, validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9fc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(vae, scaler, n_samples=1000):\n",
    "    # Instead of standard normal, use the distribution of the latent space\n",
    "    latent_samples = np.random.normal(size=(n_samples, latent_dim))\n",
    "    \n",
    "    # Predict the outputs (reconstructions)\n",
    "    predictions = vae.decoder.predict(latent_samples)\n",
    "    \n",
    "    # Check sigmoid outputs before rounding\n",
    "    print(\"Sigmoid outputs before rounding:\", predictions[:, -3:])\n",
    "\n",
    "    # Separate continuous and binary data\n",
    "    continuous_data = predictions[:, :-3]\n",
    "    binary_data = predictions[:, -3:]\n",
    "    \n",
    "    # Inverse transform the continuous data to get it back to original scale\n",
    "    continuous_data = scaler.inverse_transform(continuous_data)\n",
    "    \n",
    "    binary_data = np.zeros_like(binary_data)\n",
    "    binary_data[np.arange(len(binary_data)), np.argmax(predictions[:, -3:], axis=1)] = 1\n",
    "    \n",
    "    # Concatenate both continuous and binary data\n",
    "    return np.concatenate([continuous_data, binary_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcdde382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 1ms/step\n",
      "Sigmoid outputs before rounding: [[0.34588557 0.31692964 0.30585152]\n",
      " [0.32509091 0.37613758 0.3923231 ]\n",
      " [0.28336015 0.28538272 0.3296258 ]\n",
      " ...\n",
      " [0.34670863 0.36164647 0.40023136]\n",
      " [0.3504729  0.3272499  0.36024934]\n",
      " [0.29974407 0.37253553 0.36913022]]\n",
      "Synthetic data generated and saved to synthetic_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = generate_synthetic_data(vae, scaler, n_samples=5000)\n",
    "\n",
    "# Convert synthetic data to DataFrame\n",
    "synthetic_data_df = pd.DataFrame(synthetic_data, columns=data.columns)\n",
    "\n",
    "# Save the synthetic data to a new CSV file\n",
    "synthetic_data_df.to_csv('VAE_synthetic_data.csv', index=False)\n",
    "\n",
    "print(\"Synthetic data generated and saved to synthetic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e982a0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C                      float32\n",
      "H                      float32\n",
      "N                      float32\n",
      "O                      float32\n",
      "S                      float32\n",
      "VM                     float32\n",
      "Ash                    float32\n",
      "FC                     float32\n",
      "Cel                    float32\n",
      "Hem                    float32\n",
      "Lig                    float32\n",
      "Plantcapacity(kg/hr    float32\n",
      "MSP                    float32\n",
      "Location_China         float32\n",
      "Location_UK            float32\n",
      "Location_US            float32\n",
      "dtype: object\n",
      "           C          H         N          O         S         VM        Ash  \\\n",
      "0  49.270000   6.550000  1.560000  42.620000  0.000000  80.752916   6.044539   \n",
      "1  45.019652   6.569343  2.189781  46.221224  0.000000  76.122673  18.948521   \n",
      "2  45.739910  10.762332  7.036909  34.908589  1.552259  49.357766  42.020000   \n",
      "3  56.085157   7.108220  4.861029  30.833826  1.111768  73.526474  20.879121   \n",
      "4  45.896172   5.709845  1.622249  46.771734  0.000000  77.318919   1.783784   \n",
      "\n",
      "          FC    Cel    Hem    Lig  Plantcapacity(kg/hr     MSP  \\\n",
      "0  13.202545  36.89  20.42  17.38                50000  1.0088   \n",
      "1   4.928806  21.00  28.00  21.00                25000  0.6864   \n",
      "2   8.626970  35.00  25.00  26.50                25000  0.8500   \n",
      "3   5.594406  16.60  48.50   1.60                25000  0.7384   \n",
      "4  20.897297  21.00  12.80  32.70                25000  0.7300   \n",
      "\n",
      "   Location_China  Location_UK  Location_US  \n",
      "0               0            1            0  \n",
      "1               0            1            0  \n",
      "2               0            0            1  \n",
      "3               0            1            0  \n",
      "4               0            0            1  \n",
      "           C         H         N          O         S         VM        Ash  \\\n",
      "0  49.056637  6.280582  1.325718  42.336071  0.212049  76.088097   6.923491   \n",
      "1  50.040154  6.838076  2.521754  41.422325  0.438615  74.623688  10.732533   \n",
      "2  49.681522  6.100524  1.466231  42.348000  0.171232  76.184677   8.615174   \n",
      "3  49.754692  6.902108  2.521415  41.426098  0.423484  74.608330  13.046909   \n",
      "4  49.657333  6.749276  2.471989  41.654613  0.409350  74.697304  10.625330   \n",
      "\n",
      "          FC        Cel        Hem        Lig  Plantcapacity(kg/hr       MSP  \\\n",
      "0  16.312841  33.709312  25.504812  20.990898         37806.160156  0.769645   \n",
      "1  15.266187  32.136688  28.438009  23.498100         37304.707031  0.860821   \n",
      "2  15.851039  36.490051  26.317526  21.217527         37868.539062  0.752389   \n",
      "3  15.166089  31.844603  29.201883  23.551922         37716.683594  0.868036   \n",
      "4  15.620178  32.596783  28.351814  22.944675         37355.156250  0.852059   \n",
      "\n",
      "   Location_China  Location_UK  Location_US  \n",
      "0             1.0          0.0          0.0  \n",
      "1             0.0          0.0          1.0  \n",
      "2             0.0          0.0          1.0  \n",
      "3             0.0          0.0          1.0  \n",
      "4             0.0          0.0          1.0  \n"
     ]
    }
   ],
   "source": [
    "print(synthetic_data_df.dtypes)\n",
    "print(data.head())\n",
    "print(synthetic_data_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfc714a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Means by Country:\n",
      "                        C         H         N          O        S         VM  \\\n",
      "Country                                                                        \n",
      "Location_China  49.506202  6.418846  1.793219  42.060283  0.22145  75.465442   \n",
      "Location_UK     49.506202  6.418846  1.793219  42.060283  0.22145  75.465442   \n",
      "Location_US     49.506202  6.418846  1.793219  42.060283  0.22145  75.465442   \n",
      "\n",
      "                     Ash         FC        Cel        Hem        Lig  \\\n",
      "Country                                                                \n",
      "Location_China  8.694476  15.840234  33.685306  26.992285  21.840139   \n",
      "Location_UK     8.694476  15.840234  33.685306  26.992285  21.840139   \n",
      "Location_US     8.694476  15.840234  33.685306  26.992285  21.840139   \n",
      "\n",
      "                Plantcapacity(kg/hr       MSP  Location_China  Location_UK  \\\n",
      "Country                                                                      \n",
      "Location_China              37500.0  0.570813             1.0          0.0   \n",
      "Location_UK                 37500.0  0.927781             0.0          1.0   \n",
      "Location_US                 37500.0  0.879839             0.0          0.0   \n",
      "\n",
      "                Location_US  \n",
      "Country                      \n",
      "Location_China          0.0  \n",
      "Location_UK             0.0  \n",
      "Location_US             1.0  \n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Synthetic Data Means by Country:\n",
      "                        C         H         N          O         S         VM  \\\n",
      "Country                                                                         \n",
      "Location_China  49.324940  6.364403  1.473143  42.278610  0.222969  75.905884   \n",
      "Location_UK     49.554890  6.242843  1.733088  42.185467  0.267427  76.012863   \n",
      "Location_US     49.658619  6.567394  2.158984  41.814442  0.339950  75.021004   \n",
      "\n",
      "                      Ash         FC        Cel        Hem        Lig  \\\n",
      "Country                                                                 \n",
      "Location_China   8.215303  16.220583  34.274525  25.928045  21.403387   \n",
      "Location_UK      6.403716  16.072874  34.490211  25.635803  21.603067   \n",
      "Location_US     10.625698  15.586238  33.335400  27.848810  22.641506   \n",
      "\n",
      "                Plantcapacity(kg/hr       MSP  Location_China  Location_UK  \\\n",
      "Country                                                                      \n",
      "Location_China         37761.167969  0.774961             1.0          0.0   \n",
      "Location_UK            36988.980469  0.770615             0.0          1.0   \n",
      "Location_US            37591.484375  0.824755             0.0          0.0   \n",
      "\n",
      "                Location_US  \n",
      "Country                      \n",
      "Location_China          0.0  \n",
      "Location_UK             0.0  \n",
      "Location_US             1.0  \n"
     ]
    }
   ],
   "source": [
    "data[['Location_China', 'Location_UK', 'Location_US']] = data[['Location_China', 'Location_UK', 'Location_US']].round().astype(int)\n",
    "synthetic_data_df[['Location_China', 'Location_UK', 'Location_US']] = synthetic_data_df[['Location_China', 'Location_UK', 'Location_US']].round().astype(int)\n",
    "\n",
    "# Convert one-hot encoding back to categorical for groupby operation in original data\n",
    "data['Country'] = (data[['Location_China', 'Location_UK', 'Location_US']].round() == 1).idxmax(axis=1)\n",
    "\n",
    "# Group by country and calculate mean for the original data\n",
    "means = data.groupby('Country').mean()\n",
    "\n",
    "# Convert one-hot encoding back to categorical for groupby operation in synthetic data\n",
    "synthetic_data_df['Country'] = (synthetic_data_df[[ 'Location_China','Location_UK','Location_US']] == 1).idxmax(axis=1)\n",
    "\n",
    "# Group by country and calculate mean for the synthetic data\n",
    "synthetic_means = synthetic_data_df.groupby('Country').mean()\n",
    "\n",
    "print(\"Original Data Means by Country:\")\n",
    "print(means)\n",
    "\n",
    "# For a clean separation in the output\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Synthetic Data Means by Country:\")\n",
    "print(synthetic_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c888feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C                         49.506202\n",
      "H                          6.418846\n",
      "N                          1.793219\n",
      "O                         42.060283\n",
      "S                          0.221450\n",
      "VM                        75.465442\n",
      "Ash                        8.694476\n",
      "FC                        15.840234\n",
      "Cel                       33.685306\n",
      "Hem                       26.992285\n",
      "Lig                       21.840139\n",
      "Plantcapacity(kg/hr    37500.000000\n",
      "MSP                        0.792811\n",
      "Location_China             0.333333\n",
      "Location_UK                0.333333\n",
      "Location_US                0.333333\n",
      "dtype: float64\n",
      "C                         49.591564\n",
      "H                          6.455460\n",
      "N                          1.963361\n",
      "O                         41.969433\n",
      "S                          0.306616\n",
      "VM                        75.393829\n",
      "Ash                        9.196394\n",
      "FC                        15.792426\n",
      "Cel                       33.758919\n",
      "Hem                       27.023275\n",
      "Lig                       22.214952\n",
      "Plantcapacity(kg/hr    37447.199219\n",
      "MSP                        0.804232\n",
      "Location_China             0.116200\n",
      "Location_UK                0.272200\n",
      "Location_US                0.611600\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balun\\AppData\\Local\\Temp\\ipykernel_23008\\171735337.py:1: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(data.mean())\n",
      "C:\\Users\\balun\\AppData\\Local\\Temp\\ipykernel_23008\\171735337.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(synthetic_data_df.mean())\n"
     ]
    }
   ],
   "source": [
    "print(data.mean())\n",
    "print(synthetic_data_df.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
